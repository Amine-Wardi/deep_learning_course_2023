{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3352c55-74f5-4627-bffe-2a62646b9ca8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f56ae059e60c644d20fcf6566e83bde",
     "grade": false,
     "grade_id": "cell-e7f749f1d24233da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# IS319 - Deep Learning\n",
    "\n",
    "## TP1 - Neural networks\n",
    "\n",
    "The goal of this TP is to implement a simple feedforward neural network, but without the use of libraries like PyTorch or TensorFlow. We will only use NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a45a5ac-e124-4dd4-8c70-162cf1f303f7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce74b31c12c9ae5fc28d9f0bde3045ae",
     "grade": false,
     "grade_id": "cell-00063860a6102415",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b494d22-a981-4cef-9a2f-180e2c03463c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "24c151e63001e49f2b7a0f980115a09b",
     "grade": false,
     "grade_id": "cell-6677b191d92dc6b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 1. Activation function and its derivative\n",
    "\n",
    "**(Question)** Implement the following activation function and its respective gradient (vector of partial derivatives). These should be applied element-wise to the input vector `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "977beeb6-6308-4a62-a6ec-cd5d7ef4f0af",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3988b2b90122a3e662f7b4f6046337ba",
     "grade": false,
     "grade_id": "activation-functions",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(a):\n",
    "    '''Return the element-wise sigmoid of the input vector.'''\n",
    "    return 1/(1 + np.exp(-a))\n",
    "\n",
    "def d_sigmoid(a):\n",
    "    '''Return the partial derivatives of the sigmoid function\n",
    "    with respect to the input vector.'''\n",
    "    return sigmoid(a)*(1 - sigmoid(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d135483f-3b82-44f3-b7be-469e71de5e42",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b80432cdeab94236cb3e8a7bab77a818",
     "grade": true,
     "grade_id": "activation-functions-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.random.randn(100)\n",
    "assert np.all(sigmoid(a) >= 0.)\n",
    "assert np.all(sigmoid(a) <= 1.)\n",
    "assert sigmoid(0.) == 0.5\n",
    "assert np.all(d_sigmoid(a) >= 0.)\n",
    "assert np.all(d_sigmoid(a) <= 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2496f14-4f65-45aa-81de-7ed6776512f3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf310d3ade385374a6b17ba58a56a68f",
     "grade": false,
     "grade_id": "cell-b5b0c0c62db57fb8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2. Loss function and its derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43e836c-55d0-47c7-a66a-9eadd6e808e2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "338407dbc743f6cc63b292b769db9dc2",
     "grade": false,
     "grade_id": "cell-cf207a1a25ede0bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Implement the following loss function and its respective gradient (vector of partial derivatives).\n",
    "\n",
    "`y` and `d` correspond to predictions and ground-truth labels respectively. They are assumed to be be matrices of size `n_classes * n_samples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f765ff51-e5f0-4639-bf94-b73ea1a4d729",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f2df864b322a5c84e3f480a4949ea3d",
     "grade": false,
     "grade_id": "loss-function",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def squared_error(y, d):\n",
    "    '''Return a scalar corresponding to the sum of squared errors.'''\n",
    "    # The sum instead of mean will be more convenient for this TP\n",
    "    return np.sum((y - d)**2)/2\n",
    "\n",
    "def d_squared_error(y, d):\n",
    "    '''Return the vector of partial derivatives of the sum of\n",
    "    squared errors with respect to the predictions.'''\n",
    "    return y - d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83c7a3fc-c76f-4d24-afca-25c409a8aff9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5de2abb69d10d0fd30354508f1380637",
     "grade": true,
     "grade_id": "loss-function-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = np.random.randn(3, 100)\n",
    "d = np.random.randn(3, 100)\n",
    "assert squared_error(y, d) >= 0.\n",
    "assert d_squared_error(y, d).shape == y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dfe238-cce1-447f-bc74-c92e2faff4b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67d580cd8275b54d13f713f509624466",
     "grade": false,
     "grade_id": "cell-f5669aa56560f23f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 3. Neural network architecture\n",
    "\n",
    "We will implement a simple fully-connected neural network with **one hidden layer** and **one output layer**.\n",
    "\n",
    "This neural network is defined by a number of inputs, a number of hidden units, and a number of output units.\n",
    "\n",
    "The activation function will be sigmoid and the loss function will be the sum of squared errors, both implemented above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8bfafb-4db0-4dfa-bf99-232ae3e07d4f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63330aca7274f43e4e3394272547f540",
     "grade": false,
     "grade_id": "cell-0324c33b4dfea6b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(Question)** Complete the class below to initialize the weights and biases randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34b35e8b-ca06-4e03-9121-5d012b89b40d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c2f866fee5e620ed936080942e9395a",
     "grade": false,
     "grade_id": "init-weights",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, n_input, n_hidden, n_output):\n",
    "        '''Initialize a neural network with `n_input` input neurons,\n",
    "        `n_hidden` hidden neurons and `n_output` output neurons.'''\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_output = n_output\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        '''Initialize random weights with correct sizes in attributes `W1`, `b1`, `W2` and `b2`.'''\n",
    "        self.W1 = np.random.rand(self.n_input, self.n_hidden)\n",
    "        self.W2 = np.random.rand(self.n_hidden, self.n_output)\n",
    "        self.b1 = np.random.rand(self.n_hidden, 1)\n",
    "        self.b2 = np.random.rand(self.n_output, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98ee2249-0ffe-45b9-84aa-43df08dc2ffe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d2115947b0270481e8245bc4645ff50",
     "grade": true,
     "grade_id": "init-weights-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(64, 32, 3)\n",
    "assert nn.W1.ndim == 2\n",
    "assert nn.b1.ndim == 2\n",
    "assert nn.W2.ndim == 2\n",
    "assert nn.b2.ndim == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dd53bb-9867-436a-ba06-f12ab5c6ecb9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3fd4391516076bbeb51ee9757c5a9075",
     "grade": false,
     "grade_id": "cell-b38df17eaae875f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 4. Forward pass\n",
    "\n",
    "The forward pass is defined as:\n",
    "$$\\begin{align*}\n",
    "\\mathbf{h}_1 &= \\sigma(\\mathbf{a}_1) \\quad\\text{with}\\quad \\mathbf{a}_1 = \\mathbf{W}_1 \\mathbf{x} + \\mathbf{b}_1 \\\\\n",
    "\\mathbf{y} &= \\sigma(\\mathbf{a}_2) \\quad\\text{with}\\quad \\mathbf{a}_2 = \\mathbf{W}_2 \\mathbf{h}_1 + \\mathbf{b}_2\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3e029d-6502-428a-997f-023f05b61e17",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46951d84d019a91fb33375289a4cfc50",
     "grade": false,
     "grade_id": "cell-6c74b62788369be3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(Question)** Implement the forward pass for input examples `X`. Save intermediate results `a1`, `h1` and `a2` into attributes (as they will be needed for the backpropagation algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a17e7b8-f65d-46c5-8dbf-beaa9ae108e1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5184d383ebc7f26abfd5b14931a7a9d9",
     "grade": false,
     "grade_id": "cell-ec6cc8adc2e96480",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork): # (the method will be added to the `NeuralNetwork` class)\n",
    "    def forward(self, X):\n",
    "        self.a1 = np.dot((self.W1).T, X) + self.b1\n",
    "        self.h1 = sigmoid(self.a1)\n",
    "        self.a2 = np.dot((self.W2).T, self.h1) + self.b2\n",
    "        return sigmoid(self.a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4ebfecd-ccf7-4d54-a817-7a8418733511",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d29e31eba2ebf4babaa79ce8d7926b5a",
     "grade": true,
     "grade_id": "forward-pass",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(64, 32, 3)\n",
    "X = np.random.randn(64, 100)\n",
    "y = nn.forward(X)\n",
    "assert y.shape == (3, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0776cbe4-c4dc-4022-bbb6-7a72ea9cd33f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c461ed61d7c941f5dce94612747ec329",
     "grade": false,
     "grade_id": "cell-a74aac18b5d769d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Implement the function below to obtain a classification decision from the network. To do that, apply the forward pass, then choose the class corresponding to the maximum output value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51c63f4d-c588-4f53-a491-04b771a748ec",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b2e33de7026f7fe84828861f386dd8f",
     "grade": false,
     "grade_id": "predic",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork): # (the method will be added to the `NeuralNetwork` class)\n",
    "    def predict(self, X):\n",
    "        y_pred = self.forward(X)\n",
    "        return np.argmax(y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24649afc-05ba-458d-b221-65faf4708579",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83077ae274e07b798338dc6f984905a4",
     "grade": true,
     "grade_id": "predict-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(64, 32, 3)\n",
    "X = np.random.randn(64, 100)\n",
    "y = nn.predict(X)\n",
    "assert y.shape == (100,)\n",
    "assert np.any(y == 0) or np.any(y == 1) or np.any(y == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da06ec3-f507-4fff-8083-fee28c07f227",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "111821d4eb26f9ab464706dba8926c59",
     "grade": false,
     "grade_id": "cell-716664c03ec25271",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 5. Backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810de3e4-4745-429d-b413-1fcd01ab78b4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e0a53e5a52c8894f784dce2e57159d13",
     "grade": false,
     "grade_id": "cell-a379bc9c9644efe2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Implement the backward pass for input examples `X`, ground-truth `d`, predictions `y`.\n",
    "\n",
    "*Advice 1:* start by working on weights `d_W2` and `d_W1`, then work on the biases `d_b2` and `d_b1`.\n",
    "\n",
    "*Advice 2:* keep track of the shapes of each partial derivatives using comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b0baa1a-0693-42d6-acb6-af801ddd3b38",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6db3f094eb2165efd7873c6c6e4a33cc",
     "grade": false,
     "grade_id": "backward",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def backward(self, X, y, d):\n",
    "        '''Compute the partial derivatives of the loss function\n",
    "        with respect to all weights of the neural network.\n",
    "        Return these in variables `d_W1`, `d_b1`, `d_W2` and `d_b2`.'''\n",
    "        # Backpropagation for the output layer\n",
    "        # You should compute d_ey, d_ya2, d_a2w2 and finally delta2\n",
    "        # Then, you can compute d_W2 and d_b2\n",
    "        d_ey = d_squared_error(y, d)\n",
    "        d_ya2 = d_sigmoid(self.a2)\n",
    "        d_a2w2 = self.h1\n",
    "        delta2 = d_ey*d_ya2\n",
    "        d_W2 = np.dot(d_a2w2, delta2.T)\n",
    "        d_b2 = np.ones(self.b2.shape)\n",
    "        \n",
    "        # Backpropagation for the hidden layer\n",
    "        # You should compute d_h1a1 and finally delta1\n",
    "        # Then, you can compute d_W1 and d_b1\n",
    "        d_h1a1 = d_sigmoid(self.a1)\n",
    "        delta1 = np.dot(d_W2, delta2)*d_h1a1\n",
    "        d_W1 = np.dot(X, delta1.T)\n",
    "        d_b1 = np.ones(self.b1.shape)\n",
    "        return d_W1, d_b1, d_W2, d_b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d48b45f8-e1ad-4995-b0f7-ebf2f4a5af1f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b80ad348305b39d3b6cc79bc53b0df33",
     "grade": true,
     "grade_id": "backward-tests",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(64, 32, 3)\n",
    "X = np.random.randn(64, 100)\n",
    "d = np.random.randint(0, 2, size=(3, 100))\n",
    "y = nn.forward(X)\n",
    "loss = squared_error(y, d)\n",
    "d_W1, d_b1, d_W2, d_b2 = nn.backward(X, y, d)\n",
    "assert d_W1.shape == nn.W1.shape\n",
    "assert d_b1.shape == nn.b1.shape\n",
    "assert d_W2.shape == nn.W2.shape\n",
    "assert d_b2.shape == nn.b2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f24a0eb-ef0d-4de5-991e-07d6bf058af5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b31330285a0cc91e3ad7ec91dca3d78",
     "grade": false,
     "grade_id": "cell-0f7f2ccc7c2703a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 6. Weights update with gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbb7b81-bc3e-402c-87b5-b41a59364635",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "205541f1ac459a92fd5e3bf5a29541ec",
     "grade": false,
     "grade_id": "cell-855bcf3ab4e1f779",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(Question)** Complete the following code to implement one iteration of the training process:\n",
    "- Apply the forward pass on training data and compute the loss\n",
    "- Apply backpropagation to compute the gradient of the loss with respect to the network parameters\n",
    "- Apply gradient descent to update the network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afbfeefb-6232-4b1a-9662-2db27ee41321",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6009615e77ace62600bc917dbc2d306e",
     "grade": false,
     "grade_id": "train-iteration",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def train_iteration(self, X, d, lr=1e-2):\n",
    "        # Apply the forward pass and compute the loss\n",
    "        y = self.forward(X)\n",
    "        loss = squared_error(y, d)\n",
    "        # Apply backpropagation to compute the gradients\n",
    "        d_W1, d_b1, d_W2, d_b2 = self.backward(X, y, d)\n",
    "        # Apply gradient descent to update the weights\n",
    "        self.W1 -= lr*d_W1\n",
    "        self.W2 -= lr*d_W2\n",
    "        self.b1 -= lr*d_b1\n",
    "        self.b2 -= lr*d_b2      \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e69d878-5a2e-457d-b0ad-76f2915909a4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de24a0544915c44c8d2f86935b79e7a6",
     "grade": true,
     "grade_id": "train-iteration-tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(64, 32, 3)\n",
    "X = np.random.randn(64, 100)\n",
    "d = np.random.randint(0, 2, size=(3, 100))\n",
    "loss = nn.train_iteration(X, d, lr=100)\n",
    "assert loss >= 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375846fe-7894-4467-9245-ce02b845d587",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07572dc8db8e5ec03b5e7dd135cbe8f8",
     "grade": false,
     "grade_id": "cell-f6f5fa4a0e6feedc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 7. Mini-batch training loop\n",
    "\n",
    "Now, we will implement the main training loop of our neural network.\n",
    "\n",
    "We will use stochastic gradient descent with mini-batch: the weights will be updated by performing gradient descent on shuffled subsets of training data.\n",
    "\n",
    "We will train the network for a number of epochs (an epoch is performed when the whole training set has been used with this mini-batch procedure)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca926833-fb23-4acf-925a-fdb6fa6ba4c6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "969c109816b302f070575f1c39afe96a",
     "grade": false,
     "grade_id": "cell-42184f408b95fa4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(Question)** Complete the code below to implement the training loop with minibatch stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "130674e9-0101-4192-baf0-312abdbd0134",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e957b7273b5f45ad30f182a0d35cc1a",
     "grade": true,
     "grade_id": "training-loop",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def fit(self, X, d, batch_size, n_epochs=10, lr=1e-2):\n",
    "        n_samples = X.shape[1]\n",
    "        n_batches = (n_samples // batch_size) + 1\n",
    "        epoch_loss = 0.\n",
    "        for e in range(n_epochs):\n",
    "            # Shuffle dataset\n",
    "            permutation = np.random.permutation(n_samples)\n",
    "            X, d = X[:, permutation], d[:, permutation]\n",
    "            # Loop over each batch\n",
    "            for b in range(0, n_samples, batch_size): # range(start, stop, step)\n",
    "                # Grab the current batch in `X_batch` and `d_batch`\n",
    "                X_batch = X[:, b:batch_size+b]\n",
    "                d_batch = d[:, b:batch_size+b]\n",
    "                # Apply training iteration and update epoch loss\n",
    "                epoch_loss += self.train_iteration(X_batch, d_batch)\n",
    "            # Compute average epoch loss and print it\n",
    "            avg_epoch_loss = epoch_loss/n_epochs\n",
    "            print(f\"Average epoch loss {e}/{n_epochs} : {avg_epoch_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2116cae8-1f48-45a4-b1d7-bf5cd35e97d4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "54b57ad4d5d9a87af99087e8fa8f033e",
     "grade": false,
     "grade_id": "cell-c980fa7b2fa057b9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 8. Train the network on the MNIST dataset\n",
    "\n",
    "The MNIST dataset is composed of 70000 greyscale images of handwritten digits: 60000 images for training and 10000 for testing.\n",
    "\n",
    "It is included in the `mnist.tgz` archive provided with this TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e1e3e19-c599-4633-b815-a5af3afe1cdb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef0c69a8ba2ce881cb101b8a63d2ef5f",
     "grade": false,
     "grade_id": "cell-5562efce16521bb8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist-test-images.npy\n",
      "mnist-test-labels.npy\n",
      "mnist-train-images.npy\n",
      "mnist-train-labels.npy\n"
     ]
    }
   ],
   "source": [
    "!tar xvzf ./mnist.tgz\n",
    "images_train = np.load('./mnist-train-images.npy')\n",
    "labels_train = np.load('./mnist-train-labels.npy')\n",
    "images_test = np.load('./mnist-test-images.npy')\n",
    "labels_test = np.load('./mnist-test-labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60674f9f-1b2d-481c-8d9f-6427ea608d93",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4acf046d404e63e8f9cf998a58328f22",
     "grade": false,
     "grade_id": "cell-c3a9fec3fa080314",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Reshape the images into vectors and normalize the pixel values between 0 and 1. Convert the labels into one-hot vectors (*i.e.* vectors full of 0 and with only a 1 for the corresponding class). Store the results into `X_train`, `y_train`, `X_test` and `y_test` variables. Make sure to reshape to the following:\n",
    "- Input data: `n_features x n_samples`\n",
    "- Labels: `n_classes x n_samples`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84e60aea-3db1-4bb2-a394-ce7f51ac3ca8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23e56a7ce963ee1576ef578d6cb42b90",
     "grade": false,
     "grade_id": "mnist-dataset",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (784, 60000),\n",
      "X_test shape : (784, 10000),\n",
      "y_train shape : (9, 60000),\n",
      "y_test shape :(9, 10000)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "def onehot(y, d=9) :\n",
    "    y_onehot = []\n",
    "    for v in y :\n",
    "        acc = [0]*d\n",
    "        acc[v-1] = 1\n",
    "        y_onehot.append(acc)\n",
    "    return np.array(y_onehot)\n",
    "    \n",
    "X_train = (images_train.reshape(images_train.shape[0], -1)/255).T\n",
    "X_test = (images_test.reshape(images_test.shape[0], -1)/255).T\n",
    "y_train, y_test = onehot(labels_train).T, onehot(labels_test).T\n",
    "\n",
    "print(f\"X_train shape : {X_train.shape},\\nX_test shape : {X_test.shape},\\ny_train shape : {y_train.shape},\\ny_test shape :{y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b753e345-4d69-47d3-bc2d-4a05f4c09766",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f68ed5893b3a3657bd36d0fe74efd59d",
     "grade": true,
     "grade_id": "mnist-dataset-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert np.all(X_train >= 0.) and np.all(X_train <= 1.)\n",
    "assert np.all(X_test >= 0.) and np.all(X_test <= 1.)\n",
    "assert np.all(np.unique(y_train) == np.array([0., 1.])) \n",
    "assert np.all(np.unique(y_test) == np.array([0., 1.]))\n",
    "assert np.all(np.sum(y_train, axis=0) == 1.)\n",
    "assert np.all(np.sum(y_test, axis=0) == 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c092ea-0342-4d64-89b9-c8ed5a1a2ad4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd5c0f6c9bd960d9ea0b3cc726d41e90",
     "grade": false,
     "grade_id": "cell-6c0d93b6eb6561df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Initialize a neural network for MNIST with 32 hidden units and train it for 10 epochs with a batch size of 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77f0664e-95cb-4b4f-a711-ca5d7b067df2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a283bf0348d1f16794309fcddc49b38f",
     "grade": true,
     "grade_id": "mnist-train",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss 0/10 : 23999.97791908592\n",
      "Average epoch loss 1/10 : 47999.901304736355\n",
      "Average epoch loss 2/10 : 71999.56789972707\n",
      "Average epoch loss 3/10 : 94700.82945538966\n",
      "Average epoch loss 4/10 : 113845.6797444529\n",
      "Average epoch loss 5/10 : 130949.2202206999\n",
      "Average epoch loss 6/10 : 145359.81400675385\n",
      "Average epoch loss 7/10 : 153254.6107237627\n",
      "Average epoch loss 8/10 : 158530.41849472918\n",
      "Average epoch loss 9/10 : 163800.82750769178\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(784, 32, 9)\n",
    "nn.fit(X_train, y_train, batch_size=512, n_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f971d1f-a2be-4e14-8b32-d16cf95133bb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0702549a613d49feff7dfd5b4178c833",
     "grade": false,
     "grade_id": "cell-c428e777c7ce4fc2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Compute the classification accuracy on the train and test sets. To do that, you can use the predict function and compare them with the original labels (*i.e.* without one-hot encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0079310-dc37-4e09-a3d8-802d20f5c9ca",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "374097f8ed66b3dc5b906d6fbfcb630e",
     "grade": true,
     "grade_id": "mnist-accuracy",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for MNIST : 0.1032\n"
     ]
    }
   ],
   "source": [
    "y_pred = nn.predict(X_test)\n",
    "print(f\"Accuracy score for MNIST : {sum(labels_test == y_pred)/len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea0b13d-ff16-4a77-b031-d6b770d8d542",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1460ad42591ceee6c3ad8d6cd56e8f2",
     "grade": false,
     "grade_id": "cell-d57ca20154998a71",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "**(Question)** Compute and plot the confusion matrix for the test set. Which are the most difficult classes? Show some examples of misclassified images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd429c3b-0caa-4404-abd1-90634a141887",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55d3c78fffbc672cda2e5e5829a1f99e",
     "grade": true,
     "grade_id": "mnist-results",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(labels_test, y_pred)\n",
    "labels= [i for i in range(10)]\n",
    "\n",
    "# Create a figure and plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "# Add class labels to the plot\n",
    "plt.gca().invert_yaxis()\n",
    "tick_marks = np.arange(len(labels))\n",
    "plt.xticks(tick_marks, labels, rotation=45)\n",
    "plt.yticks(tick_marks, labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e2034c-1258-4e01-945f-6f1b5907dd7c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "68541cac2f30c21ce5fa54188105962c",
     "grade": false,
     "grade_id": "cell-7d1885888535c8ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Play around with hyperparameters of the model. What happens when the batch size if very small? And very large?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6dd58d50-39f8-401b-b84e-b3cf5c060cf6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0df07798cf703fcd5235339f0d58aaa8",
     "grade": true,
     "grade_id": "mnist-hyperparameters",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss 0/10 : 23999.981596529782\n",
      "Average epoch loss 1/10 : 47999.94733671789\n",
      "Average epoch loss 2/10 : 71999.88167809934\n",
      "Average epoch loss 3/10 : 95999.74760717862\n",
      "Average epoch loss 4/10 : 119999.41989362973\n",
      "Average epoch loss 5/10 : 143427.45274700256\n",
      "Average epoch loss 6/10 : 163399.77551232377\n",
      "Average epoch loss 7/10 : 182539.23146413587\n",
      "Average epoch loss 8/10 : 200429.48489229096\n",
      "Average epoch loss 9/10 : 217099.81341403903\n",
      "Accuracy score for MNIST : 0.098\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(784, 32, 9)\n",
    "nn.fit(X_train, y_train, batch_size=1024, n_epochs=10)\n",
    "y_pred = nn.predict(X_test)\n",
    "print(f\"Accuracy score for MNIST : {sum(labels_test == y_pred)/len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d5c9c3-b3fc-424c-b815-83c47a704229",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d40b357e3b5b8ed50650a2319ba0196",
     "grade": true,
     "grade_id": "mnist-comments",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7102a2-a15a-4998-a1ce-c060d64a4e83",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a5b965e5a491c8593296182c01270c6",
     "grade": false,
     "grade_id": "cell-0bf423527a0279d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 9. Extension to more than one hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f9f104-9ab8-46f1-97a3-93b714e6b018",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf0b3fda55676027ae5b8e965c874403",
     "grade": false,
     "grade_id": "extend-multiple-layers",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "**(Question)** Extend your neural network model to handle more than one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb60a109-f66a-4527-a9ae-891d4525d667",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7483f6ba66ef4dd2a928c91f00a9f5c",
     "grade": true,
     "grade_id": "cell-ab36027b7515bf15",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fccc60a-4f7d-4e31-827f-39b2791c1713",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44dc156b6626b3e62b9a19658c28a9ce",
     "grade": false,
     "grade_id": "cell-60e9495352b554be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 10. Extension to softmax and categorical cross-entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d36216-95f5-4db1-b83d-39942e09df34",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9554f96bc8af873f05114d2fb594b2e",
     "grade": false,
     "grade_id": "extend-crossentropy",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "**(Question)** Extend your neural network model to use a softmax activation function for the output layer, and a categorical cross-entropy loss.\n",
    "You can also experiment with the reLU activation for the hidden layer.\n",
    "\n",
    "*Hint:* recall the partial derivatives formulation from logistic regression, and optimize the backpropagation for the output layer accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c24019-4f36-497f-ad3e-a42ce1a8ad79",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f3434f56af08fae4b878f1f4e02f7f3",
     "grade": true,
     "grade_id": "cell-30584782a093acaf",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d3a944cc3058aa50c0aca891e5a7b77ff393d72d074c3644bd97999f32c63dcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
