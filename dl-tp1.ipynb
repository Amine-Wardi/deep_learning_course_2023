{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3352c55-74f5-4627-bffe-2a62646b9ca8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f56ae059e60c644d20fcf6566e83bde",
     "grade": false,
     "grade_id": "cell-e7f749f1d24233da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# IS319 - Deep Learning\n",
    "\n",
    "## TP1 - Neural networks\n",
    "\n",
    "The goal of this TP is to implement a simple feedforward neural network, but without the use of libraries like PyTorch or TensorFlow. We will only use NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a45a5ac-e124-4dd4-8c70-162cf1f303f7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce74b31c12c9ae5fc28d9f0bde3045ae",
     "grade": false,
     "grade_id": "cell-00063860a6102415",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b494d22-a981-4cef-9a2f-180e2c03463c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "24c151e63001e49f2b7a0f980115a09b",
     "grade": false,
     "grade_id": "cell-6677b191d92dc6b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 1. Activation function and its derivative\n",
    "\n",
    "**(Question)** Implement the following activation function and its respective gradient (vector of partial derivatives). These should be applied element-wise to the input vector `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "977beeb6-6308-4a62-a6ec-cd5d7ef4f0af",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3988b2b90122a3e662f7b4f6046337ba",
     "grade": false,
     "grade_id": "activation-functions",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(a):\n",
    "    '''Return the element-wise sigmoid of the input vector.'''\n",
    "    return 1/(1 + np.exp(-a))\n",
    "\n",
    "def d_sigmoid(a):\n",
    "    '''Return the partial derivatives of the sigmoid function\n",
    "    with respect to the input vector.'''\n",
    "    return sigmoid(a)*(1 - sigmoid(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d135483f-3b82-44f3-b7be-469e71de5e42",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b80432cdeab94236cb3e8a7bab77a818",
     "grade": true,
     "grade_id": "activation-functions-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.random.randn(100)\n",
    "assert np.all(sigmoid(a) >= 0.)\n",
    "assert np.all(sigmoid(a) <= 1.)\n",
    "assert sigmoid(0.) == 0.5\n",
    "assert np.all(d_sigmoid(a) >= 0.)\n",
    "assert np.all(d_sigmoid(a) <= 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2496f14-4f65-45aa-81de-7ed6776512f3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf310d3ade385374a6b17ba58a56a68f",
     "grade": false,
     "grade_id": "cell-b5b0c0c62db57fb8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2. Loss function and its derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43e836c-55d0-47c7-a66a-9eadd6e808e2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "338407dbc743f6cc63b292b769db9dc2",
     "grade": false,
     "grade_id": "cell-cf207a1a25ede0bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Implement the following loss function and its respective gradient (vector of partial derivatives).\n",
    "\n",
    "`y` and `d` correspond to predictions and ground-truth labels respectively. They are assumed to be be matrices of size `n_classes * n_samples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f765ff51-e5f0-4639-bf94-b73ea1a4d729",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f2df864b322a5c84e3f480a4949ea3d",
     "grade": false,
     "grade_id": "loss-function",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def squared_error(y, d):\n",
    "    '''Return a scalar corresponding to the sum of squared errors.'''\n",
    "    # The sum instead of mean will be more convenient for this TP\n",
    "    return np.sum((y - d)**2)\n",
    "\n",
    "def d_squared_error(y, d):\n",
    "    '''Return the vector of partial derivatives of the sum of\n",
    "    squared errors with respect to the predictions.'''\n",
    "    return 2*(y - d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83c7a3fc-c76f-4d24-afca-25c409a8aff9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5de2abb69d10d0fd30354508f1380637",
     "grade": true,
     "grade_id": "loss-function-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = np.random.randn(3, 100)\n",
    "d = np.random.randn(3, 100)\n",
    "assert squared_error(y, d) >= 0.\n",
    "assert d_squared_error(y, d).shape == y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dfe238-cce1-447f-bc74-c92e2faff4b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67d580cd8275b54d13f713f509624466",
     "grade": false,
     "grade_id": "cell-f5669aa56560f23f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 3. Neural network architecture\n",
    "\n",
    "We will implement a simple fully-connected neural network with **one hidden layer** and **one output layer**.\n",
    "\n",
    "This neural network is defined by a number of inputs, a number of hidden units, and a number of output units.\n",
    "\n",
    "The activation function will be sigmoid and the loss function will be the sum of squared errors, both implemented above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8bfafb-4db0-4dfa-bf99-232ae3e07d4f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63330aca7274f43e4e3394272547f540",
     "grade": false,
     "grade_id": "cell-0324c33b4dfea6b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(Question)** Complete the class below to initialize the weights and biases randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34b35e8b-ca06-4e03-9121-5d012b89b40d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c2f866fee5e620ed936080942e9395a",
     "grade": false,
     "grade_id": "init-weights",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, n_input, n_hidden, n_output):\n",
    "        '''Initialize a neural network with `n_input` input neurons,\n",
    "        `n_hidden` hidden neurons and `n_output` output neurons.'''\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_output = n_output\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        '''Initialize random weights with correct sizes in attributes `W1`, `b1`, `W2` and `b2`.'''\n",
    "        self.W1 = np.random.randn(self.n_hidden, self.n_input)\n",
    "        self.b1 = np.random.randn(self.n_hidden, 1)\n",
    "        self.W2 = np.random.randn(self.n_output, self.n_hidden)\n",
    "        self.b2 = np.random.randn(self.n_output, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98ee2249-0ffe-45b9-84aa-43df08dc2ffe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d2115947b0270481e8245bc4645ff50",
     "grade": true,
     "grade_id": "init-weights-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(64, 32, 3)\n",
    "assert nn.W1.ndim == 2\n",
    "assert nn.b1.ndim == 2\n",
    "assert nn.W2.ndim == 2\n",
    "assert nn.b2.ndim == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dd53bb-9867-436a-ba06-f12ab5c6ecb9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3fd4391516076bbeb51ee9757c5a9075",
     "grade": false,
     "grade_id": "cell-b38df17eaae875f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 4. Forward pass\n",
    "\n",
    "The forward pass is defined as:\n",
    "$$\\begin{align*}\n",
    "\\mathbf{h}_1 &= \\sigma(\\mathbf{a}_1) \\quad\\text{with}\\quad \\mathbf{a}_1 = \\mathbf{W}_1 \\mathbf{x} + \\mathbf{b}_1 \\\\\n",
    "\\mathbf{y} &= \\sigma(\\mathbf{a}_2) \\quad\\text{with}\\quad \\mathbf{a}_2 = \\mathbf{W}_2 \\mathbf{h}_1 + \\mathbf{b}_2\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3e029d-6502-428a-997f-023f05b61e17",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46951d84d019a91fb33375289a4cfc50",
     "grade": false,
     "grade_id": "cell-6c74b62788369be3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(Question)** Implement the forward pass for input examples `X`. Save intermediate results `a1`, `h1` and `a2` into attributes (as they will be needed for the backpropagation algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a17e7b8-f65d-46c5-8dbf-beaa9ae108e1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5184d383ebc7f26abfd5b14931a7a9d9",
     "grade": false,
     "grade_id": "cell-ec6cc8adc2e96480",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork): # (the method will be added to the `NeuralNetwork` class)\n",
    "    def forward(self, X):\n",
    "        self.a1 = np.dot(self.W1, X) + self.b1\n",
    "        self.h1 = sigmoid(self.a1)\n",
    "        self.a2 = np.dot(self.W2, self.h1) + self.b2\n",
    "        return sigmoid(self.a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4ebfecd-ccf7-4d54-a817-7a8418733511",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d29e31eba2ebf4babaa79ce8d7926b5a",
     "grade": true,
     "grade_id": "forward-pass",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(64, 32, 3)\n",
    "X = np.random.randn(64, 100)\n",
    "y = nn.forward(X)\n",
    "assert y.shape == (3, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0776cbe4-c4dc-4022-bbb6-7a72ea9cd33f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c461ed61d7c941f5dce94612747ec329",
     "grade": false,
     "grade_id": "cell-a74aac18b5d769d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Implement the function below to obtain a classification decision from the network. To do that, apply the forward pass, then choose the class corresponding to the maximum output value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51c63f4d-c588-4f53-a491-04b771a748ec",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b2e33de7026f7fe84828861f386dd8f",
     "grade": false,
     "grade_id": "predic",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork): # (the method will be added to the `NeuralNetwork` class)\n",
    "    def predict(self, X):\n",
    "        y_pred = self.forward(X)\n",
    "        return np.argmax(y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24649afc-05ba-458d-b221-65faf4708579",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83077ae274e07b798338dc6f984905a4",
     "grade": true,
     "grade_id": "predict-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(64, 32, 3)\n",
    "X = np.random.randn(64, 100)\n",
    "y = nn.predict(X)\n",
    "assert y.shape == (100,)\n",
    "assert np.any(y == 0) or np.any(y == 1) or np.any(y == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da06ec3-f507-4fff-8083-fee28c07f227",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "111821d4eb26f9ab464706dba8926c59",
     "grade": false,
     "grade_id": "cell-716664c03ec25271",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 5. Backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810de3e4-4745-429d-b413-1fcd01ab78b4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e0a53e5a52c8894f784dce2e57159d13",
     "grade": false,
     "grade_id": "cell-a379bc9c9644efe2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Implement the backward pass for input examples `X`, ground-truth `d`, predictions `y`.\n",
    "\n",
    "*Advice 1:* start by working on weights `d_W2` and `d_W1`, then work on the biases `d_b2` and `d_b1`.\n",
    "\n",
    "*Advice 2:* keep track of the shapes of each partial derivatives using comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b0baa1a-0693-42d6-acb6-af801ddd3b38",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6db3f094eb2165efd7873c6c6e4a33cc",
     "grade": false,
     "grade_id": "backward",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def backward(self, X, y, d):\n",
    "        '''Compute the partial derivatives of the loss function\n",
    "        with respect to all weights of the neural network.\n",
    "        Return these in variables `d_W1`, `d_b1`, `d_W2` and `d_b2`.'''\n",
    "        # Backpropagation for the output layer\n",
    "        # You should compute d_ey, d_ya2, d_a2w2 and finally delta2\n",
    "        # Then, you can compute d_W2 and d_b2\n",
    "        d_ey = d_squared_error(y, d)\n",
    "        d_ya2 = d_sigmoid(self.a2)\n",
    "        d_a2w2 = self.h1.T \n",
    "        delta2 = d_ey * d_ya2\n",
    "        d_W2 = np.dot(delta2, d_a2w2)\n",
    "        d_b2 = delta2.sum(axis=1, keepdims=True)\n",
    "\n",
    "        # Backpropagation for the hidden layer\n",
    "        # You should compute d_h1a1 and finally delta1\n",
    "        # Then, you can compute d_W1 and d_b1\n",
    "        d_h1a1 = d_sigmoid(self.a1)  \n",
    "        delta1 = np.dot(self.W2.T, delta2) * d_h1a1\n",
    "        d_W1 = np.dot(delta1, X.T)\n",
    "        d_b1 = delta1.sum(axis=1, keepdims=True)\n",
    "\n",
    "        return d_W1, d_b1, d_W2, d_b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d48b45f8-e1ad-4995-b0f7-ebf2f4a5af1f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b80ad348305b39d3b6cc79bc53b0df33",
     "grade": true,
     "grade_id": "backward-tests",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(64, 32, 3)\n",
    "X = np.random.randn(64, 100)\n",
    "d = np.random.randint(0, 2, size=(3, 100))\n",
    "y = nn.forward(X)\n",
    "loss = squared_error(y, d)\n",
    "d_W1, d_b1, d_W2, d_b2 = nn.backward(X, y, d)\n",
    "assert d_W1.shape == nn.W1.shape\n",
    "assert d_b1.shape == nn.b1.shape\n",
    "assert d_W2.shape == nn.W2.shape\n",
    "assert d_b2.shape == nn.b2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f24a0eb-ef0d-4de5-991e-07d6bf058af5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b31330285a0cc91e3ad7ec91dca3d78",
     "grade": false,
     "grade_id": "cell-0f7f2ccc7c2703a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 6. Weights update with gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbb7b81-bc3e-402c-87b5-b41a59364635",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "205541f1ac459a92fd5e3bf5a29541ec",
     "grade": false,
     "grade_id": "cell-855bcf3ab4e1f779",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(Question)** Complete the following code to implement one iteration of the training process:\n",
    "- Apply the forward pass on training data and compute the loss\n",
    "- Apply backpropagation to compute the gradient of the loss with respect to the network parameters\n",
    "- Apply gradient descent to update the network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afbfeefb-6232-4b1a-9662-2db27ee41321",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6009615e77ace62600bc917dbc2d306e",
     "grade": false,
     "grade_id": "train-iteration",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def train_iteration(self, X, d, lr=1e-2):\n",
    "        # Apply the forward pass and compute the loss\n",
    "        y = self.forward(X)\n",
    "        loss = squared_error(y, d)\n",
    "        # Apply backpropagation to compute the gradients\n",
    "        d_W1, d_b1, d_W2, d_b2 = self.backward(X, y, d)\n",
    "\n",
    "        # Apply gradient descent for convergence\n",
    "        self.W1 -= lr*d_W1\n",
    "        self.W2 -= lr*d_W2\n",
    "        self.b1 -= lr*d_b1\n",
    "        self.b2 -= lr*d_b2      \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e69d878-5a2e-457d-b0ad-76f2915909a4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de24a0544915c44c8d2f86935b79e7a6",
     "grade": true,
     "grade_id": "train-iteration-tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(64, 32, 3)\n",
    "X = np.random.randn(64, 100)\n",
    "d = np.random.randint(0, 2, size=(3, 100))\n",
    "loss = nn.train_iteration(X, d, lr=100)\n",
    "assert loss >= 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375846fe-7894-4467-9245-ce02b845d587",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07572dc8db8e5ec03b5e7dd135cbe8f8",
     "grade": false,
     "grade_id": "cell-f6f5fa4a0e6feedc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 7. Mini-batch training loop\n",
    "\n",
    "Now, we will implement the main training loop of our neural network.\n",
    "\n",
    "We will use stochastic gradient descent with mini-batch: the weights will be updated by performing gradient descent on shuffled subsets of training data.\n",
    "\n",
    "We will train the network for a number of epochs (an epoch is performed when the whole training set has been used with this mini-batch procedure)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca926833-fb23-4acf-925a-fdb6fa6ba4c6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "969c109816b302f070575f1c39afe96a",
     "grade": false,
     "grade_id": "cell-42184f408b95fa4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(Question)** Complete the code below to implement the training loop with minibatch stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "130674e9-0101-4192-baf0-312abdbd0134",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e957b7273b5f45ad30f182a0d35cc1a",
     "grade": true,
     "grade_id": "training-loop",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def fit(self, X, d, batch_size, n_epochs=10, lr=1e-2, verbose=True):\n",
    "        n_samples = X.shape[1]\n",
    "        n_batches = (n_samples // batch_size) + 1\n",
    "        for e in range(n_epochs):\n",
    "            # Shuffle dataset\n",
    "            permutation = np.random.permutation(n_samples)\n",
    "            X, d = X[:, permutation], d[:, permutation]\n",
    "            # Loop over each batch\n",
    "            epoch_loss = 0.\n",
    "            for b in range(0, n_samples, batch_size): # range(start, stop, step)\n",
    "                # Grab the current batch in `X_batch` and `d_batch`\n",
    "                X_batch = X[:, b:b+batch_size]\n",
    "                d_batch = d[:, b:b+batch_size]\n",
    "                # Apply training iteration and update epoch loss\n",
    "                epoch_loss += self.train_iteration(X_batch, d_batch)\n",
    "            # Compute average epoch loss and print it\n",
    "            avg_epoch_loss = epoch_loss/n_batches\n",
    "            if verbose :\n",
    "                print(f\"Average epoch loss {e+1}/{n_epochs} : {avg_epoch_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2116cae8-1f48-45a4-b1d7-bf5cd35e97d4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "54b57ad4d5d9a87af99087e8fa8f033e",
     "grade": false,
     "grade_id": "cell-c980fa7b2fa057b9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 8. Train the network on the MNIST dataset\n",
    "\n",
    "The MNIST dataset is composed of 70000 greyscale images of handwritten digits: 60000 images for training and 10000 for testing.\n",
    "\n",
    "It is included in the `mnist.tgz` archive provided with this TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e1e3e19-c599-4633-b815-a5af3afe1cdb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef0c69a8ba2ce881cb101b8a63d2ef5f",
     "grade": false,
     "grade_id": "cell-5562efce16521bb8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist-test-images.npy\n",
      "mnist-test-labels.npy\n",
      "mnist-train-images.npy\n",
      "mnist-train-labels.npy\n"
     ]
    }
   ],
   "source": [
    "!tar xvzf ./mnist.tgz\n",
    "images_train = np.load('./mnist-train-images.npy')\n",
    "labels_train = np.load('./mnist-train-labels.npy')\n",
    "images_test = np.load('./mnist-test-images.npy')\n",
    "labels_test = np.load('./mnist-test-labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60674f9f-1b2d-481c-8d9f-6427ea608d93",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4acf046d404e63e8f9cf998a58328f22",
     "grade": false,
     "grade_id": "cell-c3a9fec3fa080314",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Reshape the images into vectors and normalize the pixel values between 0 and 1. Convert the labels into one-hot vectors (*i.e.* vectors full of 0 and with only a 1 for the corresponding class). Store the results into `X_train`, `y_train`, `X_test` and `y_test` variables. Make sure to reshape to the following:\n",
    "- Input data: `n_features x n_samples`\n",
    "- Labels: `n_classes x n_samples`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84e60aea-3db1-4bb2-a394-ce7f51ac3ca8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23e56a7ce963ee1576ef578d6cb42b90",
     "grade": false,
     "grade_id": "mnist-dataset",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (784, 60000),\n",
      "X_test shape : (784, 10000),\n",
      "y_train shape : (10, 60000),\n",
      "y_test shape :(10, 10000)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "def onehot(y, d=10) :\n",
    "    y_onehot = []\n",
    "    for v in y :\n",
    "        acc = [0]*d\n",
    "        acc[v] = 1\n",
    "        y_onehot.append(acc)\n",
    "    return np.array(y_onehot)\n",
    "    \n",
    "X_train = (images_train.reshape(images_train.shape[0], -1)/255).T\n",
    "X_test = (images_test.reshape(images_test.shape[0], -1)/255).T\n",
    "y_train, y_test = onehot(labels_train).T, onehot(labels_test).T\n",
    "\n",
    "print(f\"X_train shape : {X_train.shape},\\nX_test shape : {X_test.shape},\\ny_train shape : {y_train.shape},\\ny_test shape :{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b753e345-4d69-47d3-bc2d-4a05f4c09766",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f68ed5893b3a3657bd36d0fe74efd59d",
     "grade": true,
     "grade_id": "mnist-dataset-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert np.all(X_train >= 0.) and np.all(X_train <= 1.)\n",
    "assert np.all(X_test >= 0.) and np.all(X_test <= 1.)\n",
    "assert np.all(np.unique(y_train) == np.array([0., 1.])) \n",
    "assert np.all(np.unique(y_test) == np.array([0., 1.]))\n",
    "assert np.all(np.sum(y_train, axis=0) == 1.)\n",
    "assert np.all(np.sum(y_test, axis=0) == 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c092ea-0342-4d64-89b9-c8ed5a1a2ad4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd5c0f6c9bd960d9ea0b3cc726d41e90",
     "grade": false,
     "grade_id": "cell-6c0d93b6eb6561df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Initialize a neural network for MNIST with 32 hidden units and train it for 10 epochs with a batch size of 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77f0664e-95cb-4b4f-a711-ca5d7b067df2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a283bf0348d1f16794309fcddc49b38f",
     "grade": true,
     "grade_id": "mnist-train",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss 1/10 : 365.28064213651425\n",
      "Average epoch loss 2/10 : 211.53433936739125\n",
      "Average epoch loss 3/10 : 157.34328577565324\n",
      "Average epoch loss 4/10 : 116.96904709839579\n",
      "Average epoch loss 5/10 : 103.00352632192936\n",
      "Average epoch loss 6/10 : 94.45379526550285\n",
      "Average epoch loss 7/10 : 88.27864892407284\n",
      "Average epoch loss 8/10 : 83.30098360887199\n",
      "Average epoch loss 9/10 : 79.55034317304761\n",
      "Average epoch loss 10/10 : 76.29700389826667\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(784, 32, 10)\n",
    "nn.fit(X_train, y_train, batch_size=512, n_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f971d1f-a2be-4e14-8b32-d16cf95133bb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0702549a613d49feff7dfd5b4178c833",
     "grade": false,
     "grade_id": "cell-c428e777c7ce4fc2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Compute the classification accuracy on the train and test sets. To do that, you can use the predict function and compare them with the original labels (*i.e.* without one-hot encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0079310-dc37-4e09-a3d8-802d20f5c9ca",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "374097f8ed66b3dc5b906d6fbfcb630e",
     "grade": true,
     "grade_id": "mnist-accuracy",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for MNIST : 0.91\n"
     ]
    }
   ],
   "source": [
    "y_pred = nn.predict(X_test)\n",
    "print(f\"Accuracy score for MNIST : {sum(labels_test == y_pred)/len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea0b13d-ff16-4a77-b031-d6b770d8d542",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1460ad42591ceee6c3ad8d6cd56e8f2",
     "grade": false,
     "grade_id": "cell-d57ca20154998a71",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "**(Question)** Compute and plot the confusion matrix for the test set. Which are the most difficult classes? Show some examples of misclassified images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd429c3b-0caa-4404-abd1-90634a141887",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55d3c78fffbc672cda2e5e5829a1f99e",
     "grade": true,
     "grade_id": "mnist-results",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(labels_test, y_pred)\n",
    "labels= [i for i in range(10)]\n",
    "\n",
    "# Create a figure and plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "# Add class labels to the plot\n",
    "plt.gca().invert_yaxis()\n",
    "tick_marks = np.arange(len(labels))\n",
    "plt.xticks(tick_marks, labels, rotation=45)\n",
    "plt.yticks(tick_marks, labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e2034c-1258-4e01-945f-6f1b5907dd7c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "68541cac2f30c21ce5fa54188105962c",
     "grade": false,
     "grade_id": "cell-7d1885888535c8ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Play around with hyperparameters of the model. What happens when the batch size if very small? And very large?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6dd58d50-39f8-401b-b84e-b3cf5c060cf6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0df07798cf703fcd5235339f0d58aaa8",
     "grade": true,
     "grade_id": "mnist-hyperparameters",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for MNIST with batch_size 32: 0.8309\n",
      "Accuracy score for MNIST with batch_size 64: 0.9219\n",
      "Accuracy score for MNIST with batch_size 128: 0.9281\n",
      "Accuracy score for MNIST with batch_size 256: 0.9311\n",
      "Accuracy score for MNIST with batch_size 512: 0.935\n",
      "Accuracy score for MNIST with batch_size 1024: 0.9381\n",
      "Accuracy score for MNIST with batch_size 2048: 0.939\n",
      "Accuracy score for MNIST with batch_size 4096: 0.8561\n",
      "Accuracy score for MNIST with batch_size 8192: 0.0975\n",
      "Accuracy score for MNIST with batch_size 16384: 0.0974\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(784, 32, 10)\n",
    "batch_sizes = [2**x for x in range(5, 15)]\n",
    "for batch_size in batch_sizes :\n",
    "    print(f\"fitting...\", end='\\r')\n",
    "    nn.fit(X_train, y_train, batch_size=batch_size, n_epochs=10, verbose=False)\n",
    "    y_pred = nn.predict(X_test)\n",
    "    print(f\"Accuracy score for MNIST with batch_size {batch_size}: {sum(labels_test == y_pred)/len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d5c9c3-b3fc-424c-b815-83c47a704229",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d40b357e3b5b8ed50650a2319ba0196",
     "grade": true,
     "grade_id": "mnist-comments",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## **Answer :**\n",
    "**Hi**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7102a2-a15a-4998-a1ce-c060d64a4e83",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a5b965e5a491c8593296182c01270c6",
     "grade": false,
     "grade_id": "cell-0bf423527a0279d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 9. Extension to more than one hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f9f104-9ab8-46f1-97a3-93b714e6b018",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf0b3fda55676027ae5b8e965c874403",
     "grade": false,
     "grade_id": "extend-multiple-layers",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "**(Question)** Extend your neural network model to handle more than one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb60a109-f66a-4527-a9ae-891d4525d667",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7483f6ba66ef4dd2a928c91f00a9f5c",
     "grade": true,
     "grade_id": "cell-ab36027b7515bf15",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "class NeuralNetworkMutli(NeuralNetwork):\n",
    "    def __init__(self, layer_sizes, activation_function=None, loss_function=None, d_activation_function=None):\n",
    "        '''Initialize a neural network with the specified layer sizes.\n",
    "        `layer_sizes` is a list that includes the number of neurons in each layer.'''\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.num_layers = len(layer_sizes)\n",
    "        self.init_weights()\n",
    "        self.activation_function = activation_function\n",
    "        self.loss_function = loss_function\n",
    "        if d_activation_function == None :\n",
    "            self.d_activation_function = lambda x : activation_function(x)*(1 - activation_function(x))\n",
    "        else :\n",
    "            self.d_activation_function = d_activation_function\n",
    "        self.d_loss_function = lambda y, d : y - d\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.weights = [np.random.rand(y, x) for x, y in zip(self.layer_sizes[:-1], self.layer_sizes[1:])]\n",
    "        self.bs = [np.random.rand(y, 1) for y in self.layer_sizes[1:]]\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.activations = [X]\n",
    "        self.zs = []\n",
    "        for w, b in zip(self.weights, self.bs):\n",
    "            z = np.dot(w, self.activations[-1]) + b\n",
    "            self.zs.append(z)\n",
    "            a = self.activation_function(z)\n",
    "            self.activations.append(a)\n",
    "        return self.zs[-1]\n",
    "\n",
    "    def backward(self, y, d):\n",
    "        self.d_weights = [np.zeros(w.shape) for w in self.weights]\n",
    "        self.d_bs = [np.zeros(b.shape) for b in self.bs]\n",
    "        \n",
    "        delta = self.d_loss_function(y, d) * self.d_activation_function(self.activations[-1])\n",
    "\n",
    "        self.d_weights[-1] = np.dot(delta, self.activations[-2].T)\n",
    "        self.d_bs[-1] = delta.sum(axis=1, keepdims=True)\n",
    "        \n",
    "        \n",
    "        for l in range(2, self.num_layers):\n",
    "            delta = np.dot(self.weights[-l + 1].T, delta) * self.d_activation_function(self.activations[-l])\n",
    "            self.d_weights[-l] = np.dot(delta, self.activations[-l - 1].T)\n",
    "            self.d_bs[-l] = delta.sum(axis=1, keepdims=True)\n",
    "        \n",
    "    def train_iteration(self, X, d, lr=1e-2):\n",
    "        y_pred = self.forward(X)\n",
    "        self.backward(y_pred, d)\n",
    "        \n",
    "        self.weights = [w - lr * dw for w, dw in zip(self.weights, self.d_weights)]\n",
    "        self.bs = [b - lr * db for b, db in zip(self.bs, self.d_bs)]\n",
    "        \n",
    "        loss = self.loss_function(y_pred, d)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "391663e3-9700-435f-ab5f-cc902409d260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss 1/10 : 26.775460007568476\n",
      "Average epoch loss 2/10 : 11.148452788466535\n",
      "Average epoch loss 3/10 : 8.365280377660952\n",
      "Average epoch loss 4/10 : 7.4813887266791275\n",
      "Average epoch loss 5/10 : 7.121206256399702\n",
      "Average epoch loss 6/10 : 6.907872185872705\n",
      "Average epoch loss 7/10 : 6.7545692911463995\n",
      "Average epoch loss 8/10 : 6.6293201666451465\n",
      "Average epoch loss 9/10 : 6.572569615580205\n",
      "Average epoch loss 10/10 : 6.485556575901982\n",
      "Accuracy score for MNIST : 0.8079\n"
     ]
    }
   ],
   "source": [
    "nnm = NeuralNetworkMutli([784, 32, 10], activation_function=sigmoid, loss_function=squared_error)\n",
    "nnm.fit(X_train, y_train, batch_size=16, n_epochs=10)\n",
    "y_pred = nnm.predict(X_test)\n",
    "print(f\"Accuracy score for MNIST : {sum(labels_test == y_pred)/len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fccc60a-4f7d-4e31-827f-39b2791c1713",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44dc156b6626b3e62b9a19658c28a9ce",
     "grade": false,
     "grade_id": "cell-60e9495352b554be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 10. Extension to softmax and categorical cross-entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d36216-95f5-4db1-b83d-39942e09df34",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9554f96bc8af873f05114d2fb594b2e",
     "grade": false,
     "grade_id": "extend-crossentropy",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "**(Question)** Extend your neural network model to use a softmax activation function for the output layer, and a categorical cross-entropy loss.\n",
    "You can also experiment with the reLU activation for the hidden layer.\n",
    "\n",
    "*Hint:* recall the partial derivatives formulation from logistic regression, and optimize the backpropagation for the output layer accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96c24019-4f36-497f-ad3e-a42ce1a8ad79",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f3434f56af08fae4b878f1f4e02f7f3",
     "grade": true,
     "grade_id": "cell-30584782a093acaf",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=0, keepdims=True))\n",
    "    return exp_x / exp_x.sum(axis=0, keepdims=True)\n",
    "\n",
    "def reLU(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def d_reLU(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "    \n",
    "def categorical_crossentropy(y, d):\n",
    "    epsilon = 1e-15  # A small value to prevent log(0)\n",
    "    y = np.clip(y, epsilon, 1 - epsilon)\n",
    "    return -np.sum(d * np.log(y)) / y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9aece1b-8792-41a5-a768-664fe42f232c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss 1/10 : 3.4453041206475117\n",
      "Average epoch loss 2/10 : 1.990644601740757\n",
      "Average epoch loss 3/10 : 1.556813163626347\n",
      "Average epoch loss 4/10 : 1.354213202502721\n",
      "Average epoch loss 5/10 : 1.252771479152389\n",
      "Average epoch loss 6/10 : 1.191710396315312\n",
      "Average epoch loss 7/10 : 1.1358768963041534\n",
      "Average epoch loss 8/10 : 1.1012636367892417\n",
      "Average epoch loss 9/10 : 1.0869349556965489\n",
      "Average epoch loss 10/10 : 1.066642602888333\n",
      "Accuracy score for MNIST : 0.7019\n"
     ]
    }
   ],
   "source": [
    "nnm = NeuralNetworkMutli([784, 32, 10], activation_function=softmax, loss_function=categorical_crossentropy)\n",
    "nnm.fit(X_train, y_train, batch_size=16, n_epochs=10)\n",
    "y_pred = nnm.predict(X_test)\n",
    "print(f\"Accuracy score for MNIST : {sum(labels_test == y_pred)/len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec8566f3-0e77-4a73-bb80-0679ee89d9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss 1/10 : 34.53647388656839\n",
      "Average epoch loss 2/10 : 34.53762514073975\n",
      "Average epoch loss 3/10 : 34.53762514073975\n",
      "Average epoch loss 4/10 : 34.53762514073975\n",
      "Average epoch loss 5/10 : 34.53762514073975\n",
      "Average epoch loss 6/10 : 34.53762514073975\n",
      "Average epoch loss 7/10 : 34.53762514073975\n",
      "Average epoch loss 8/10 : 34.53762514073975\n",
      "Average epoch loss 9/10 : 34.53762514073975\n",
      "Average epoch loss 10/10 : 34.53762514073975\n",
      "Accuracy score for MNIST : 0.0958\n"
     ]
    }
   ],
   "source": [
    "nnm = NeuralNetworkMutli([784, 32, 10], activation_function=reLU, loss_function=categorical_crossentropy, d_activation_function=d_reLU)\n",
    "nnm.fit(X_train, y_train, batch_size=2, n_epochs=10)\n",
    "y_pred = nnm.predict(X_test)\n",
    "print(f\"Accuracy score for MNIST : {sum(labels_test == y_pred)/len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134d6ce0-c756-48d6-b0dd-34afbe381b93",
   "metadata": {},
   "source": [
    "ReLU (Rectified Linear Unit):\n",
    "\n",
    "ReLU is typically used as an activation function for hidden layers in deep neural networks.\n",
    "\n",
    "It introduces non-linearity and sparsity in the network by outputting zero for negative inputs and passing positive inputs as.\n",
    "\n",
    "ReLU is computationally efficient and has been widely used in deep learning due to its effectiveness in training deep network.\n",
    "\n",
    "Softmax :\n",
    "\n",
    "Softmax is used in the output layer of a neural network for multi-class classification tasks.\n",
    "\n",
    "It transforms the network's raw output scores into a probability distribution over multiple classes.\n",
    "\n",
    "Softmax is suitable for problems where you need to assign a probability to each class, and it ensures that the class probabilities sum to 1.\n",
    "\n",
    "It's not typically used as an activation function in hiddelayers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b05cf6-a197-471b-8728-212f810e3047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "d3a944cc3058aa50c0aca891e5a7b77ff393d72d074c3644bd97999f32c63dcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
